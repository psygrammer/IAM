{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE PREDICTRON: END-TO-END LEARNING AND PLANNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머/IAM : 파트 1 - 딥마인드 논문리뷰 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* ABSTRACT\n",
    "* 1 INTRODUCTION\n",
    "* 2 BACKGROUND\n",
    "* 3 PREDICTRON ARCHITECTURE\n",
    "* 4 PREDICTRON LEARNING UPDATES\n",
    "    - 4.1 SUPERVISED (MONTE-CARLO) LEARNING WITH THE PREDICTRON\n",
    "    - 4.2 CONSISTENCY (SEMI-SUPERVISED) LEARNING WITH THE PREDICTRON\n",
    "* 5 EXPERIMENTS\n",
    "    - 5.1 EXPLORING THE PREDICTRON ARCHITECTURE\n",
    "    - 5.2 COMPARING THE PREDICTRON TO OTHER DEEP NETWORKS\n",
    "    - 5.3 SEMI-SUPERVISED LEARNING BY CONSISTENCY\n",
    "    - 5.4 ANALYSIS OF ADAPTIVE DEPTH\n",
    "    - 5.5 VISUALIZING THE PREDICTIONS IN THE POOL DOMAIN\n",
    "* 6 RELATED WORK\n",
    "* 7 DISCUSSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABSTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One of the key challenges of artificial intelligence is to <font color=\"red\">learn models</font> that are effective <font color=\"red\">in the context of planning</font>.\n",
    "* In this document we introduce the <font color=\"red\">predictron architecture</font>.\n",
    "* The predictron consists of a <font color=\"red\">fully abstract model</font>, \n",
    "    - represented by a <font color=\"red\">Markov reward process</font>, \n",
    "        - that can be <font color=\"red\">rolled forward multiple “imagined” planning steps</font>.\n",
    "* Each forward pass of the predictron \n",
    "    - <font color=\"red\">accumulates internal rewards and values</font> \n",
    "        - over multiple planning depths.\n",
    "* The predictron is <font color=\"red\">trained end-to-end</font> so as to make these accumulated values accurately <font color=\"red\">approximate the true value function</font>.\n",
    "* We applied the predictron to procedurally generated \n",
    "    - <font color=\"red\">random mazes</font> and \n",
    "    - a simulator for <font color=\"red\">the game of pool</font>.\n",
    "* The predictron yielded significantly <font color=\"red\">more accurate predictions than</font> <font color=\"blue\">conventional deep neural network architectures</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [3] Markov reward model - https://en.wikipedia.org/wiki/Markov_reward_model\n",
    "* [4] Lecture 2: Markov Decision Processes - http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MDP.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model-based RL\n",
    "* The central idea of model-based reinforcement learning is to decompose the RL problem into two subproblems: \n",
    "    - learning a model of the environment, and then \n",
    "    - planning with this model. \n",
    "* The model \n",
    "    - is typically represented by a Markov reward process (MRP) or decision process (MDP). \n",
    "* The planning component \n",
    "    - uses this model \n",
    "        - to evaluate and select \n",
    "            - among possible strategies. \n",
    "\n",
    "#### Rrolling forward the model          \n",
    "* planning\n",
    "    - This is typically achieved by rolling forward the model \n",
    "        - to construct a value function that \n",
    "            - estimates cumulative reward. \n",
    "\n",
    "#### trained essentially independently\n",
    "* In prior work, \n",
    "    - the model is trained essentially independently of \n",
    "        - its use within the planner. \n",
    "    - As a result, \n",
    "        - the model is not well-matched \n",
    "            - with the overall objective of the agent. \n",
    "\n",
    "#### VS. model-free\n",
    "* Prior deep reinforcement learning methods have successfully constructed models that can unroll near pixel-perfect reconstructions but are <font color=\"red\">yet to surpass state-of-the-art model-free methods</font> in challenging RL domains with raw inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Predictron\n",
    "* In this paper we introduce a new architecture, which we call the predictron, that <font color=\"red\">integrates learning and planning</font> <font color=\"blue\">into one end-to-end training procedure</font>. \n",
    "* At every step, a model is applied to an internal state, to produce a next state, reward, discount, and value estimate. \n",
    "* This model is completely abstract and its <font color=\"red\">only goal is to facilitate accurate value prediction</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 BACKGROUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 PREDICTRON ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap4.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each $λ_k$ weight acts as a gate on the computation of the λ-preturn: \n",
    "    - a value of λk = 0 will truncate the λ-preturn at layer k, while a value of $λ_k$ = I will utilise deeper layers based on additional steps of the model m; \n",
    "    - the final weight is always $λ_K$ = 0. \n",
    "    - The individual $λ_k$ weights may depend on the corresponding abstract state $s_k$ and can differ per prediction. \n",
    "    - <font color=\"red\">This enables the predictron to compute to an adaptive depth (Graves, 2016) depending on the internal state and learning dynamics of the network</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 PREDICTRON LEARNING UPDATES\n",
    "* 4.1 SUPERVISED (MONTE-CARLO) LEARNING WITH THE PREDICTRON\n",
    "* 4.2 CONSISTENCY (SEMI-SUPERVISED) LEARNING WITH THE PREDICTRON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 SUPERVISED (MONTE-CARLO) LEARNING WITH THE PREDICTRON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update all the k-step preturns $g^0$, . . . , $g^K$ towards a target outcome g, such as the Monte Carlo return from the outcomes of episodes in the environment, by minimising a mean-squared error loss,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap5.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 CONSISTENCY (SEMI-SUPERVISED) LEARNING WITH THE PREDICTRON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ideally, the predictron (f,m,v) learns preturns that are <font color=\"blue\">all equal in expectation</font> to the true value function of the environment, \n",
    "    - $E_m$[$g_k$|s] = $E_p$[$g_t$|$s_t$ = s] = $v_p(s)$, \n",
    "        - in which case the preturns must be equal in expectation, \n",
    "            - $E_m$[$g_0$|s] = $E_m$[$g_1$|s]  = ... = $E_m$[$g_K$|s] . \n",
    "* This may be interpreted as satisfying \n",
    "    - a Bellman equation, \n",
    "        - <font color=\"blue\">unrolled K times</font>,\n",
    "            - on the model m. \n",
    "* In addition, <font color=\"blue\">each k-step preturn must be equal in expectation</font> to the λ-preturn, \n",
    "    - $E_m$[$g_k$|s] = $E_m$[$g^λ$|s] , for any λ parameters. \n",
    "* <font color=\"blue\">All these consistency relations</font> \n",
    "    - between preturns \n",
    "    - give rise to <font color=\"blue\">additional constraints</font> upon the predictron.\n",
    "* Specifically, <font color=\"red\">we may adjust the parameters</font> of the predictron to lead to consistent preturns, <font color=\"red\">even in the absence of labelled targets</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concretely, we can adjust each preturn $g^k$ towards the λ-preturn $g^λ$; in other words, we can update each individual value estimate towards the best aggregated estimate by minimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here $g^λ$ is considered fixed; the parameters θ are only updated to make $g^k$ more similar to gλ, not vice versa. \n",
    "* This consistency update <font color=\"red\">does not require any labels g or samples from the environment</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, it can be applied to (potentially hypothetical) states that have <font color=\"blue\">no associated ‘real’ (e.g. Monte-Carlo) outcome</font>: \n",
    "* <font color=\"red\">we update the value estimates to be self-consistent with each other</font>. \n",
    "* Note the similarity with the semi-supervised setting, where <font color=\"red\">we may have unlabelled inputs</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 EXPERIMENTS\n",
    "* 5.1 EXPLORING THE PREDICTRON ARCHITECTURE\n",
    "* 5.2 COMPARING THE PREDICTRON TO OTHER DEEP NETWORKS\n",
    "* 5.3 SEMI-SUPERVISED LEARNING BY CONSISTENCY\n",
    "* 5.4 ANALYSIS OF ADAPTIVE DEPTH\n",
    "* 5.5 VISUALIZING THE PREDICTIONS IN THE POOL DOMAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap7.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/core.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/pool.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 EXPLORING THE PREDICTRON ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 COMPARING THE PREDICTRON TO OTHER DEEP NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 SEMI-SUPERVISED LEARNING BY CONSISTENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 ANALYSIS OF ADAPTIVE DEPTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, the predictron can adapt its depth to ‘think more’ about some predictions than others, perhaps depending on the complexity of the underlying target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The depth distributions exhibit three properties. \n",
    "* First, different types of predictions used different depths. \n",
    "* Second, depth was correlated with the real-world discount for the first four prediction types. \n",
    "* Third, the distributions are not strongly peaked, which implies that the depth can differ per input even for a single real-world discount and prediction type. \n",
    "\n",
    "In a control experiment (not shown) we used a scalar λ shared among all predictions, which reduced performance in all scenarios, <font color=\"red\">indicating that the heterogeneous depth is a valuable form of flexibility</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 VISUALIZING THE PREDICTIONS IN THE POOL DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\nAAAD/9k=\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/BeaLdaN2C3Q\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fed004eeb70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('BeaLdaN2C3Q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 RELATED WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lee et al. (2015) introduced a neural network architecture where classifications branch off interme- diate hidden layers.\n",
    "* Value iteration networks (Tamar et al., 2016) use convolutional and max-pooling layers to represent a step of value iteration.\n",
    "* Schmidhuber (2015) dicusses learning abstract models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 DISCUSSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The predictron is a single differentiable architecture that rolls forward an internal model to estimate values. This internal model may be given both the structure and the semantics of traditional rein- forcement learning models. But unlike most approaches to model-based reinforcement learning, the model is fully abstract: <font color=\"red\">it need not correspond to the real environment in any human understandable fashion, so long as its rolled-forward “plans” accurately predict outcomes in the true environment</font>.\n",
    "\n",
    "* <font color=\"red\">The predictron may be viewed as a novel network architecture that incorporates several separable ideas.</font> \n",
    "     - First, the predictron outputs a value by accumulating rewards over a series of internal planning steps. \n",
    "     - Second, each forward pass of the predictron outputs values at multiple planning depths.\n",
    "     - Third, these values may be combined together, also within a single forward pass, to output an overall ensemble value. \n",
    "     - Finally, the different values output by the predictron may be encouraged to be self-consistent with each other, to provide an additional signal during learning. \n",
    "     - Our experiments demonstrate that these differences result in more accurate predictions of value, in reinforcement learning environments, than more conventional network architectures.\n",
    "\n",
    "* We have focused on value prediction tasks in uncontrolled environments. \n",
    "    - However, <font color=\"red\">these ideas may transfer to the control setting</font>, for example by using the predictron as a Q-network (Mnih et al., 2015). \n",
    "    - <font color=\"red\">Even more intriguing is the possibility of learning an internal MDP with abstract internal actions</font>, rather than the MRP model considered in this paper. \n",
    "    - We aim to explore these ideas in future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료 \n",
    "* [1] (paper) The Predictron: End-To-End Learning and Planning - https://arxiv.org/abs/1612.08810\n",
    "* [2] (code) zhongwen/predictron - https://github.com/zhongwen/predictron\n",
    "* [3] Markov reward model - https://en.wikipedia.org/wiki/Markov_reward_model\n",
    "* [4] Lecture 2: Markov Decision Processes - http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MDP.pdf\n",
    "* [5] (video) Predictron network on pool domain - https://youtu.be/BeaLdaN2C3Q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
